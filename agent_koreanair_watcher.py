#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Korean Air Agent bulletin watcher (ê°•í™”íŒ)
- ëŒ€ìƒ: https://agent.koreanair.com/service/usage/bulletin
- ë™ì‘:
  1) Playwrightë¡œ ì§„ì…(ko-KR, Asia/Seoul, ì»¤ìŠ¤í…€ UA) â†’ ë°°ë„ˆ/íŒì—… ìë™ ë‹«ê¸°
  2) ìƒì„¸ê¸€ ë§í¬ë§Œ ìˆ˜ì§‘: a[href*="/service/usage/bulletin/"] ì´ë©´ì„œ
     ì •í™•íˆ .../bulletin ìœ¼ë¡œ ëë‚˜ëŠ” ëª©ë¡ ë£¨íŠ¸ ë§í¬ëŠ” ì œì™¸
  3) ìµœì´ˆ 1íšŒ ìŠ¤ëƒ…ìƒ·(ìµœì‹  10ê±´) â†’ ìƒíƒœ íŒŒì¼ ì»¤ë°‹ ì „ì œ
  4) ì´í›„ì—” ìƒˆ ê¸€ë§Œ ì•Œë¦¼
  5) ì‹¤íŒ¨ ì‹œ HTML ì •ê·œì‹ Fallback (page.content() â†’ requests.get())

í•„ìš” ENV(Secrets ê¶Œì¥):
  TG_BOT_TOKEN, TG_CHAT_ID
  START_URL (ê¸°ë³¸: https://agent.koreanair.com/service/usage/bulletin)
  SNAPSHOT_TOP_N (ê¸°ë³¸ 10), MAX_ITEMS(ê¸°ë³¸ 60)
  KAL_USER, KAL_PASS  # ë¡œê·¸ì¸ í•„ìš”í•  ë•Œë§Œ(ë³´í†µ ë¶ˆí•„ìš”)
"""
import os
import re
import json
import time
import hashlib
import logging
from pathlib import Path
from typing import List, Dict, Optional
from urllib.parse import urljoin

import requests
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout

# ---------- ì„¤ì •/ìƒíƒœ ----------
STATE_FILE = Path(__file__).with_name("seen_posts.json")
BASELINE_FLAG = Path(__file__).with_name(".kal_baseline_done")

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

START_URL = os.getenv("START_URL", "https://agent.koreanair.com/service/usage/bulletin")
MAX_ITEMS = int(os.getenv("MAX_ITEMS", "60"))
SNAPSHOT_TOP_N = int(os.getenv("SNAPSHOT_TOP_N", "10"))

UA = ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
      "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36")

DETAIL_PATH_PAT = re.compile(r"/service/usage/bulletin/(?!$)[^?#/][^?#]*", re.I)

# ---------- ìœ í‹¸ ----------
class Post:
    def __init__(self, title: str, url: str, date: Optional[str] = None):
        self.title = (title or "").strip()
        self.url = (url or "").strip()
        self.id = self.url if self.url else hashlib.sha1(f"{self.title}|{self.url}".encode()).hexdigest()
        self.date = date

def absolutize(base: str, href: str) -> str:
    try:
        return urljoin(base, href)
    except Exception:
        return href

def notify_telegram(text: str):
    token = os.getenv("TG_BOT_TOKEN")
    chat_id = os.getenv("TG_CHAT_ID")
    if not (token and chat_id):
        logging.warning("í…”ë ˆê·¸ë¨ í† í°/ì±—ID ë¯¸ì„¤ì • â†’ ì•Œë¦¼ ìƒëµ")
        return
    api = f"https://api.telegram.org/bot{token}/sendMessage"
    r = requests.post(api, data={"chat_id": chat_id, "text": text})
    if r.status_code != 200:
        logging.warning("í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: %s %s", r.status_code, r.text)

def load_seen() -> Dict[str, Dict]:
    if STATE_FILE.exists():
        try:
            return json.loads(STATE_FILE.read_text(encoding="utf-8"))
        except Exception:
            logging.warning("seen_posts.json ì½ê¸° ì‹¤íŒ¨ â†’ ìƒˆë¡œ ì‹œì‘")
    return {}

def save_seen(seen: Dict[str, Dict]):
    STATE_FILE.write_text(json.dumps(seen, ensure_ascii=False, indent=2), encoding="utf-8")

# ---------- ë¡œê·¸ì¸ & ë°°ë„ˆ ì œê±° ----------
def try_login(page) -> bool:
    user = os.getenv("KAL_USER")
    pwd = os.getenv("KAL_PASS")
    if not (user and pwd):
        logging.info("ë¡œê·¸ì¸ ì •ë³´ ë¯¸ì œê³µ â†’ ë¹„ë¡œê·¸ì¸ìœ¼ë¡œ ì‹œë„")
        return False
    cands = [
        {"user": 'input[name="username"]', "pass": 'input[name="password"]', "submit": 'button[type="submit"]'},
        {"user": '#username', "pass": '#password', "submit": 'button[type="submit"]'},
        {"user": 'input[name="userId"]', "pass": 'input[name="userPwd"]', "submit": 'button, input[type="submit"]'},
    ]
    for c in cands:
        try:
            page.wait_for_selector(c["user"], timeout=2000)
            page.fill(c["user"], user)
            page.fill(c["pass"], pwd)
            page.click(c["submit"])
            page.wait_for_load_state("networkidle", timeout=8000)
            logging.info("ë¡œê·¸ì¸ ì‹œë„(ì„±ê³µ ì¶”ì •)")
            return True
        except Exception:
            continue
    logging.info("ë¡œê·¸ì¸ ì‹œë„ ì‹¤íŒ¨/ë¶ˆí•„ìš”")
    return False

def dismiss_banners(page):
    labels = ["ë™ì˜", "í™•ì¸", "ë‹«ê¸°", "Accept", "Agree", "OK"]
    for txt in labels:
        try:
            btn = page.locator(f'button:has-text("{txt}")')
            if btn.count() > 0:
                btn.first.click(timeout=1000)
        except Exception:
            pass

# ---------- ë‚ ì§œ ì¶”ì¶œ(ì˜µì…˜) ----------
DATE_PATS = [
    re.compile(r"\b(20\d{2})[./-](\d{1,2})[./-](\d{1,2})\b"),
    re.compile(r"\b(20\d{2})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼\b"),
]
def extract_date_near(text: str) -> Optional[str]:
    if not text:
        return None
    for pat in DATE_PATS:
        m = pat.search(text)
        if m:
            try:
                y, mo, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
                return f"{y:04d}-{mo:02d}-{d:02d}"
            except Exception:
                pass
    return None

# ---------- ëª©ë¡ ì¶”ì¶œ ----------
def extract_posts_via_dom(page) -> List[Post]:
    """
    DOMì—ì„œ ìƒì„¸ê¸€ ë§í¬ë§Œ ìˆ˜ì§‘:
    a[href*="/service/usage/bulletin/"] ì´ë©´ì„œ, ì •í™•íˆ .../bulletin ë£¨íŠ¸ëŠ” ì œì™¸
    """
    base = page.url
    posts: List[Post] = []

    sel = 'a[href*="/service/usage/bulletin/"]'
    try:
        page.wait_for_selector(sel, timeout=15000)
    except PWTimeout:
        pass

    try:
        page.mouse.wheel(0, 2000)
        page.wait_for_timeout(500)
    except Exception:
        pass

    anchors = page.locator(sel)
    count = anchors.count()
    for i in range(min(count, MAX_ITEMS)):
        a = anchors.nth(i)
        try:
            href = (a.get_attribute("href") or "").strip()
            title = (a.inner_text() or "").strip()
        except Exception:
            continue
        if not href or len(title) < 3:
            continue
        full = absolutize(base, href)
        if full.rstrip("/").endswith("/service/usage/bulletin"):
            continue
        if not DETAIL_PATH_PAT.search(href):
            continue
        date_hint = None
        try:
            parent_txt = a.evaluate("el => el.closest('li, tr, article, div')?.innerText || ''")
            date_hint = extract_date_near(parent_txt)
        except Exception:
            pass
        posts.append(Post(title=title, url=full, date=date_hint))

    seen = set()
    out: List[Post] = []
    for p in posts:
        if p.id in seen:
            continue
        seen.add(p.id)
        out.append(p)
        if len(out) >= MAX_ITEMS:
            break
    return out

ANCHOR_RE = re.compile(
    r'<a[^>]+href=["\'](?P<href>[^"\']*/service/usage/bulletin/[^"\']+)["\'][^>]*>(?P<text>.*?)</a>',
    re.I | re.S
)
TAG_STRIP_RE = re.compile(r"<[^>]+>")

def extract_posts_via_html(html: str, base: str) -> List[Post]:
    posts: List[Post] = []
    for m in ANCHOR_RE.finditer(html or ""):
        href = m.group("href")
        text = TAG_STRIP_RE.sub("", m.group("text")).strip()
        if not href or not text:
            continue
        full = absolutize(base, href)
        if full.rstrip("/").endswith("/service/usage/bulletin"):
            continue
        if not DETAIL_PATH_PAT.search(href):
            continue
        posts.append(Post(text, full))
        if len(posts) >= MAX_ITEMS:
            break
    seen = set()
    out: List[Post] = []
    for p in posts:
        if p.id in seen:
            continue
        seen.add(p.id)
        out.append(p)
    return out

def format_posts(posts: List[Post]) -> str:
    lines = []
    for p in posts:
        date = f" ({p.date})" if p.date else ""
        lines.append(f"- {p.title}{date}\n  {p.url}")
    return "\n".join(lines)

# ---------- ë©”ì¸ ----------
def main():
    seen = load_seen()
      # ğŸ”§ ë””ë²„ê·¸ í”Œë˜ê·¸
    STARTUP_PING = os.getenv("STARTUP_PING", "0").lower() in {"1", "true", "yes"}
    FORCE_SNAPSHOT = os.getenv("FORCE_SNAPSHOT", "0").lower() in {"1", "true", "yes"}
    DEBUG_HTML = os.getenv("DEBUG_HTML", "0").lower() in {"1", "true", "yes"}

    if STARTUP_PING:
        tg_ping("â–¶ï¸ KAL Agent watcher ì‹œì‘: " + os.getenv("START_URL", "N/A"))

      want_snapshot = (not BASELINE_FLAG.exists()) or FORCE_SNAPSHOT

    with sync_playwright() as pw:
        browser = pw.chromium.launch(
            headless=True,
            args=["--disable-blink-features=AutomationControlled"]
        )
        context = browser.new_context(
            user_agent=UA,
            locale="ko-KR",
            timezone_id="Asia/Seoul",
            java_script_enabled=True,
            viewport={"width": 1366, "height": 900},
        )
        context.set_extra_http_headers({"Accept-Language": "ko,en;q=0.9"})
        page = context.new_page()

        page.goto(START_URL, wait_until="domcontentloaded", timeout=30000)
        try_login(page)
        try:
            page.wait_for_load_state("networkidle", timeout=8000)
        except PWTimeout:
            pass
        dismiss_banners(page)

posts = extract_posts_via_dom(page)
logging.info("DOM anchors: %d", len(posts))
if STARTUP_PING:
    tg_ping(f"â„¹ï¸ DOM ì¶”ì¶œ: {len(posts)}ê±´")

# í•„ìš” ì‹œ HTML ì €ì¥ (DEBUG_HTML=1ì¼ ë•Œ)
if DEBUG_HTML:
    try:
        html = page.content()
        with open("/tmp/kal_page.html", "w", encoding="utf-8") as f:
            f.write(html)
    except Exception:
        pass

if not posts:
    try:
        html = page.content()
        posts = extract_posts_via_html(html, page.url)
        logging.info("HTML parse fallback: %d", len(posts))
        if STARTUP_PING:
            tg_ping(f"â„¹ï¸ HTML íŒŒì‹±: {len(posts)}ê±´")
    except Exception:
        posts = []

if not posts:
    try:
        resp = requests.get(START_URL, headers={"User-Agent": UA, "Accept-Language": "ko"}, timeout=15)
        if resp.ok:
            posts = extract_posts_via_html(resp.text, START_URL)
            logging.info("requests fallback: %d", len(posts))
            if STARTUP_PING:
                tg_ping(f"â„¹ï¸ requests íŒŒì‹±: {len(posts)}ê±´ (status {resp.status_code})")
    except Exception:
        pass

        browser.close()

if not posts:
    logging.info("ê²Œì‹œê¸€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    if STARTUP_PING:
        tg_ping("â— ê²Œì‹œê¸€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¡œê·¸ í™•ì¸ í•„ìš”)")
    return

    if want_snapshot:
        topn = posts[:SNAPSHOT_TOP_N]
        text = "KAL Agent ìŠ¤ëƒ…ìƒ· (ìµœì‹  10ê±´)\n\n" + format_posts(topn)
        notify_telegram(text)
        now = int(time.time())
        for p in posts:
            seen[p.id] = {"title": p.title, "url": p.url, "date": p.date, "ts": now}
        save_seen(seen)
        BASELINE_FLAG.write_text("done", encoding="utf-8")
        logging.info("ìŠ¤ëƒ…ìƒ· ì „ì†¡ ë° ìƒíƒœ íŒŒì¼ ìƒì„± ì™„ë£Œ")
        return

    new_posts = [p for p in posts if p.id not in seen]
    if new_posts:
        msg = f"KAL Agent ìƒˆ ê¸€ ì•Œë¦¼ ({len(new_posts)}ê±´)\n\n" + format_posts(new_posts)
        notify_telegram(msg)
        now = int(time.time())
        for p in new_posts:
            seen[p.id] = {"title": p.title, "url": p.url, "date": p.date, "ts": now}
        save_seen(seen)
        logging.info("ìƒˆ ê¸€ %dê±´ ì „ì†¡/ì €ì¥ ì™„ë£Œ", len(new_posts))
    else:
        logging.info("ìƒˆ ê¸€ ì—†ìŒ")

if __name__ == "__main__":
    main()

# í…”ë ˆê·¸ë¨ ê°„ë‹¨ í•‘
def tg_ping(text: str):
    try:
        token = os.getenv("TG_BOT_TOKEN")
        chat_id = os.getenv("TG_CHAT_ID")
        if not (token and chat_id):
            return
        requests.post(f"https://api.telegram.org/bot{token}/sendMessage",
                      data={"chat_id": chat_id, "text": text}, timeout=10)
    except Exception:
        pass
